# Example configuration for Back of the Neural Net
# Copy this file to .env in the project root and modify as needed

# LLM Provider Configuration
LLM_PROVIDER=lmstudio
LMSTUDIO_MODEL=llama-2-7b-chat
LMSTUDIO_BASE_URL=http://localhost:1234/v1

# Optional LLM Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1000
LLM_TIMEOUT=30

# Game Configuration
USE_TOOLS=true

# Server Configuration
SERVER_HOST=127.0.0.1
SERVER_PORT=8000

# For mock testing, use:
# LLM_PROVIDER=mock

# For OpenAI (future support):
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your_api_key_here
# OPENAI_MODEL=gpt-3.5-turbo